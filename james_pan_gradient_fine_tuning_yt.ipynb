{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chenghungpan/sagemaker-llama-2-rag/blob/main/james_pan_gradient_fine_tuning_yt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradientai --upgrade"
      ],
      "metadata": {
        "id": "wak76xYYUdXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90d25e3-acca-43e2-aca8-c635af1553f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.4.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.1/171.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0.0,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from gradientai) (1.10.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, gradientai\n",
            "Successfully installed aenum-3.1.15 gradientai-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = \"y52ZCrqw0FbVBnXACPHvnsbcLW7KCj2g\"\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = \"ffc923c7-0675-49ec-9600-2dda6b5e5166_workspace\""
      ],
      "metadata": {
        "id": "U02ytLrPA2rG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "\n",
        "def main():\n",
        "  with Gradient() as gradient:\n",
        "      base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "      new_model_adapter = base_model.create_model_adapter(\n",
        "          name=\"test model 3\"\n",
        "      )\n",
        "      print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "      sample_query = \"### Instruction: Who is James Pan? \\n\\n### Response:\"\n",
        "      print(f\"Asking: {sample_query}\")\n",
        "\n",
        "      # before fine-tuning\n",
        "      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "      print(f\"Generated (before fine-tune): {completion}\")\n",
        "\n",
        "      samples = [\n",
        "        { \"inputs\": \"### Instruction: Who is James Pan? \\n\\n### Response: James Pan is a seasoned machine learning expert who loves AI-LLM\" },\n",
        "        { \"inputs\": \"### Instruction: Who is the person named James Pan ? \\n\\n### Response: James Pan is a seasoned machine learning expert in the field of AI-LLM\" },\n",
        "        { \"inputs\": \"### Instruction: Can you tell me about James Pan? \\n\\n### Response: James Pan is a Stanford Ph.D. graduate with 12 years of machine learning experience\" }\n",
        "      ]\n",
        "\n",
        "      # this is where fine-tuning happens\n",
        "      # num_epochs is the number of times you fine-tune the model\n",
        "      # more epochs tends to get better results, but you also run the risk of \"overfitting\"\n",
        "      # play around with this number to find what works best for you\n",
        "      num_epochs = 3\n",
        "      count = 0\n",
        "      while count < num_epochs:\n",
        "          print(f\"Fine-tuning the model, iteration {count + 1}\")\n",
        "          new_model_adapter.fine_tune(samples=samples)\n",
        "          count = count + 1\n",
        "\n",
        "      # after fine-tuning\n",
        "      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "      print(f\"Generated (after fine-tune): {completion}\")\n",
        "\n",
        "      new_model_adapter.delete()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Scor9o08VVhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5412d01f-a315-48c5-ae8b-ffc418b9abcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 93e04b41-f76a-46e3-83bd-864f4b4744ff_model_adapter\n",
            "Asking: ### Instruction: Who is James Pan? \n",
            "\n",
            "### Response:\n",
            "Generated (before fine-tune):  James Pan is a professor of biostatistics and bioinformatics at Duke University. He is also the director of the Duke Center for Genomic and Computational Biology. Pan's research focuses on developing statistical and computational methods for analyzing large-scale genomic data, with applications in various areas such as gene regulation, genetic variation, and disease genetics.\n",
            "Fine-tuning the model, iteration 1\n",
            "Fine-tuning the model, iteration 2\n",
            "Fine-tuning the model, iteration 3\n",
            "Generated (after fine-tune):  James Pan is a Stanford Ph.D. graduate with 12 years of machine learning experience in AI-LLM. He is an expert in machine learning, natural language processing, and AI-LLM.\n"
          ]
        }
      ]
    }
  ]
}